{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install optuna -q"
   ],
   "metadata": {
    "id": "4l-djU4_d0IR",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a9842685-ee2a-4ff0-bcdc-2c00bc2f5ade",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.077804100Z",
     "start_time": "2023-10-08T09:18:18.245469700Z"
    }
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Загрузка данных"
   ],
   "metadata": {
    "collapsed": false,
    "id": "SWHqPqf5dy6R"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# чтение файлов\n",
    "train_df = pd.read_parquet('train.parquet')\n",
    "test_df = pd.read_parquet('test.parquet')\n",
    "\n",
    "# отбросим столбец id\n",
    "train_df.drop([\"id\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "epvct880dy6U",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.411192Z",
     "start_time": "2023-10-08T09:18:22.078805200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_df['okved'] = train_df['okved'].astype('category')"
   ],
   "metadata": {
    "id": "v-FYVEo0fIMq",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.425000500Z",
     "start_time": "2023-10-08T09:18:22.411192Z"
    }
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Обработка данных"
   ],
   "metadata": {
    "collapsed": false,
    "id": "VDrIqbUydy6W"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обработка категориальных признаков"
   ],
   "metadata": {
    "collapsed": false,
    "id": "QxzD8xgydy6W"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    'channel_code', 'city', 'city_type',\n",
    "    'index_city_code', 'ogrn_month', 'ogrn_year',\n",
    "    'branch_code', 'okved', 'segment'\n",
    "]\n",
    "\n",
    "train_df[cat_cols] = train_df[cat_cols].astype('category')\n",
    "test_df[cat_cols] = test_df[cat_cols].astype('category')"
   ],
   "metadata": {
    "id": "S6LbdtZIdy6X",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.612702600Z",
     "start_time": "2023-10-08T09:18:22.427002Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "t-UEl8eDdEYN",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.615234500Z",
     "start_time": "2023-10-08T09:18:22.612702600Z"
    }
   },
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обработка пустых значений"
   ],
   "metadata": {
    "collapsed": false,
    "id": "IXf3WQ7_dy6X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Признаки с малым кол-вом пропусков заменяем медианой или наиболее часто встречающимся значением"
   ],
   "metadata": {
    "collapsed": false,
    "id": "t6M7AemCdy6Y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Признаки с большим количеством пропусков\n",
    "Первые топ-10 признаков по пропускам:\n",
    "\n",
    "max_end_plan_non_fin_deals: Кол-во месяцев до максимальной плановой даты закрытия среди текущих сделок по всем срочным продуктам\n",
    "min_end_plan_non_fin_deals: Кол-во месяцев до минимальной плановой даты закрытия среди текущих сделок по всем срочным продуктам\n",
    "min_start_non_fin_deals: Кол-во месяцев до минимальной даты открытия среди текущих сделок по всем срочным продуктам\n",
    "max_start_non_fin_deals: Кол-во месяцев до максимальной даты закрытия среди текущих сделок по всем срочным продуктам\n",
    "\n",
    "max_end_fact_fin_deals: Кол-во месяцев до максимальной фактической даты закрытия среди закрытых сделок по всем срочным продуктам\n",
    "max_start_fin_deals: Кол-во месяцев до максимальной даты закрытия среди закрытых сделок по всем срочным продуктам\n",
    "min_end_fact_fin_deals: Кол-во месяцев до минимальной фактической даты закрытия среди закрытых сделок по всем срочным продуктам\n",
    "min_start_fin_deals: Кол-во месяцев до минимальной даты открытия среди закрытых сделок по всем срочным продуктам\n",
    "\n",
    "max_founderpres: Количество дней, прошедших с первой даты регистрации огрн\n",
    "min_founderpres: Количество дней, прошедших с последней даты регистрации огрн"
   ],
   "metadata": {
    "collapsed": false,
    "id": "X3Ustjk_dy6Z"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Заметим, что в этих признаках процент пропусков составляет от 86-93%\n",
    "Поэтому просто отбросим эти признаки, а признак регистрации ОГРН сделаем бинарным - зарегестрировано/незарегистрированно\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Xzpa7qUndy6Z"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "train_df.drop([\"max_end_plan_non_fin_deals\",\n",
    "               \"min_end_plan_non_fin_deals\",\n",
    "               \"max_start_non_fin_deals\",\n",
    "               \"min_start_non_fin_deals\",\n",
    "               \"max_end_fact_fin_deals\",\n",
    "               \"max_start_fin_deals\",\n",
    "               \"min_end_fact_fin_deals\",\n",
    "               \"min_start_fin_deals\",\n",
    "               ], axis=1, inplace=True)\n",
    "\n",
    "test_df.drop([\"max_end_plan_non_fin_deals\",\n",
    "              \"min_end_plan_non_fin_deals\",\n",
    "              \"max_start_non_fin_deals\",\n",
    "              \"min_start_non_fin_deals\",\n",
    "              \"max_end_fact_fin_deals\",\n",
    "              \"max_start_fin_deals\",\n",
    "              \"min_end_fact_fin_deals\",\n",
    "              \"min_start_fin_deals\",\n",
    "              ], axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "lVGUAZnUdy6Z",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.663757Z",
     "start_time": "2023-10-08T09:18:22.615234500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Если значение min(max)_founderpres - NaN значит человек не регистрировал себе ОГРН, иначе регистрировал."
   ],
   "metadata": {
    "collapsed": false,
    "id": "GKYyN0PJdy6a"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "        ogrn_reg  max_founderpres\n0              1        -0.963860\n1              0              NaN\n2              1        -0.271164\n3              0              NaN\n4              0              NaN\n...          ...              ...\n299995         1        -0.754824\n299996         1         0.549400\n299997         0              NaN\n299998         0              NaN\n299999         0              NaN\n\n[300000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ogrn_reg</th>\n      <th>max_founderpres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-0.963860</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-0.271164</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>299995</th>\n      <td>1</td>\n      <td>-0.754824</td>\n    </tr>\n    <tr>\n      <th>299996</th>\n      <td>1</td>\n      <td>0.549400</td>\n    </tr>\n    <tr>\n      <th>299997</th>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>299998</th>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>299999</th>\n      <td>0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>300000 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"ogrn_reg\"] = (train_df[\"max_founderpres\"].isna()*1 - 1) * -1\n",
    "train_df[[\"ogrn_reg\", \"max_founderpres\"]]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "-Bb0N5NVdy6a",
    "outputId": "97597568-88c6-4732-9543-b3b00fa813ef",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.675183700Z",
     "start_time": "2023-10-08T09:18:22.663757Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проделаем тоже самое для тестовых данных"
   ],
   "metadata": {
    "collapsed": false,
    "id": "yDLe6bPNdy6b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "test_df[\"ogrn_reg\"] = (test_df[\"max_founderpres\"].isna()*1 - 1) * -1\n",
    "test_df.drop([\"max_founderpres\", \"min_founderpres\"], axis=1, inplace=True)\n",
    "\n",
    "train_df[\"ogrn_reg\"] = train_df[\"ogrn_reg\"].astype(\"category\")\n",
    "test_df[\"ogrn_reg\"] = test_df[\"ogrn_reg\"].astype(\"category\")\n",
    "# train_df[cat_indexes] = train_df[cat_indexes].astype(\"category\")\n",
    "# test_df[cat_indexes] = test_df[cat_indexes].astype(\"category\")"
   ],
   "metadata": {
    "id": "dzTZVwGUdy6b",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.726731700Z",
     "start_time": "2023-10-08T09:18:22.676184700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверим, остались ли пропуски после обработки"
   ],
   "metadata": {
    "collapsed": false,
    "id": "NCEbQD-3dy6b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В данных есть признак - index_city_code\tкод города в почтовом индексе. Так как мы закодировали города, можно избавиться от этого признака, он будет создавать лишние зависимости"
   ],
   "metadata": {
    "id": "n83sI4gSAzIc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.drop(['max_founderpres', 'min_founderpres'], axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "exIKhkgX0waR",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.762505600Z",
     "start_time": "2023-10-08T09:18:22.698705600Z"
    }
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.drop(['index_city_code'], axis=1, inplace=True)\n",
    "\n",
    "# повторим для тестовых данных\n",
    "test_df.drop(['index_city_code'], axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "cmSri6PIAz_o",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:22.794766300Z",
     "start_time": "2023-10-08T09:18:22.741486100Z"
    }
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Заметим, что в наших данных есть такие признаки как sum_a_oper_1m и cnt_a_oper_1m - сумма операций типа А за месяц и их количество. Это распространяется и на другие типы операций. Сконструируем новый признак sum/cnt - средняя сумма операции типа A в месяц. Распространим эту логику на все типы операций."
   ],
   "metadata": {
    "id": "DwSvgDIrA2o-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_nans = train_df.isna().sum().sort_values(ascending=False).loc[lambda x: x > 0]\n",
    "#в обучающих данных\n",
    "train_nans = train_nans.loc[lambda x: x > 0]\n",
    "smaller_train_nans = train_nans\n",
    "\n",
    "for i in smaller_train_nans.index:\n",
    "    if train_df[i].dtype == \"object\" or train_df[i].dtype == \"category\":\n",
    "        train_df[i].loc[train_df[i].isna()] = train_df[i].value_counts().sort_values(ascending=False).index[0]\n",
    "    else:\n",
    "        train_df[i].loc[train_df[i].isna()] = train_df[i].median()\n",
    "\n",
    "\n",
    "# в тестовых данных\n",
    "test_nans = test_df.isna().sum().sort_values(ascending=False).loc[lambda x: x > 0]\n",
    "\n",
    "smaller_test_nans = test_nans\n",
    "\n",
    "for i in smaller_test_nans.index:\n",
    "    if test_df[i].dtype == \"category\":\n",
    "        test_df[i].loc[test_df[i].isna()] = test_df[i].value_counts().sort_values(ascending=False).index[0]\n",
    "    else:\n",
    "        test_df[i].loc[test_df[i].isna()] = test_df[i].median()\n",
    "\n",
    "test_nans = test_df.isna().sum().sort_values(ascending=False)"
   ],
   "metadata": {
    "id": "6IIUPZvmoLwZ",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:23.113154500Z",
     "start_time": "2023-10-08T09:18:22.797768100Z"
    }
   },
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\1942172783.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[i].loc[train_df[i].isna()] = train_df[i].median()\n",
      "C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\1942172783.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[i].loc[train_df[i].isna()] = train_df[i].median()\n",
      "C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\1942172783.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[i].loc[train_df[i].isna()] = train_df[i].median()\n",
      "C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\1942172783.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[i].loc[train_df[i].isna()] = train_df[i].median()\n",
      "C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\1942172783.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[i].loc[test_df[i].isna()] = test_df[i].median()\n",
      "C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\1942172783.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[i].loc[test_df[i].isna()] = test_df[i].median()\n",
      "C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\1942172783.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[i].loc[test_df[i].isna()] = test_df[i].median()\n",
      "C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\1942172783.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[i].loc[test_df[i].isna()] = test_df[i].median()\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Новые фичи\n"
   ],
   "metadata": {
    "id": "93NPBOHttWuh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "check_df = pd.DataFrame()\n",
    "check_df['deb_e_oper_growth'] = train_df['sum_deb_e_oper_1m'] > train_df['sum_deb_e_oper_3m']\n",
    "check_df['deb_f_oper_growth'] = train_df['sum_deb_f_oper_1m'] > train_df['sum_deb_f_oper_3m']\n",
    "check_df['deb_h_oper_growth'] = train_df['sum_deb_h_oper_1m'] > train_df['sum_deb_h_oper_3m']\n",
    "\n",
    "check_df['cred_e_oper_growth'] = train_df['sum_cred_e_oper_1m'] > train_df['sum_cred_e_oper_3m']\n",
    "check_df['cred_f_oper_growth'] = train_df['sum_cred_f_oper_1m'] > train_df['sum_cred_f_oper_3m']\n",
    "check_df['cred_h_oper_growth'] = train_df['sum_cred_h_oper_1m'] > train_df['sum_cred_h_oper_3m']\n",
    "\n",
    "check_df[['deb_e_oper_growth', 'deb_f_oper_growth', 'deb_h_oper_growth']] = check_df[['deb_e_oper_growth', 'deb_f_oper_growth', 'deb_h_oper_growth']].astype('category')\n",
    "check_df[['cred_e_oper_growth', 'cred_f_oper_growth', 'cred_h_oper_growth']] = check_df[['cred_e_oper_growth', 'cred_f_oper_growth', 'cred_h_oper_growth']].astype('category')\n"
   ],
   "metadata": {
    "id": "FeD42GcytY3O",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:23.124778400Z",
     "start_time": "2023-10-08T09:18:23.081781600Z"
    }
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dumies = pd.get_dummies(train_df, columns=['segment'])"
   ],
   "metadata": {
    "id": "1CBm5NZxt4wE",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:23.216466600Z",
     "start_time": "2023-10-08T09:18:23.119429400Z"
    }
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "check_df = check_df.join(dumies)\n",
    "train_df = check_df"
   ],
   "metadata": {
    "id": "D-bomnVyxtcX",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:23.234904600Z",
     "start_time": "2023-10-08T09:18:23.192893100Z"
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "check_df = pd.DataFrame()\n",
    "check_df['deb_e_oper_growth'] = test_df['sum_deb_e_oper_1m'] > test_df['sum_deb_e_oper_3m']\n",
    "check_df['deb_f_oper_growth'] = test_df['sum_deb_f_oper_1m'] > test_df['sum_deb_f_oper_3m']\n",
    "check_df['deb_h_oper_growth'] = test_df['sum_deb_h_oper_1m'] > test_df['sum_deb_h_oper_3m']\n",
    "\n",
    "check_df['cred_e_oper_growth'] = test_df['sum_cred_e_oper_1m'] > test_df['sum_cred_e_oper_3m']\n",
    "check_df['cred_f_oper_growth'] = test_df['sum_cred_f_oper_1m'] > test_df['sum_cred_f_oper_3m']\n",
    "check_df['cred_h_oper_growth'] = test_df['sum_cred_h_oper_1m'] > test_df['sum_cred_h_oper_3m']\n",
    "\n",
    "check_df[['deb_e_oper_growth', 'deb_f_oper_growth', 'deb_h_oper_growth']] = check_df[['deb_e_oper_growth', 'deb_f_oper_growth', 'deb_h_oper_growth']].astype('category')\n",
    "check_df[['cred_e_oper_growth', 'cred_f_oper_growth', 'cred_h_oper_growth']] = check_df[['cred_e_oper_growth', 'cred_f_oper_growth', 'cred_h_oper_growth']].astype('category')\n",
    "\n",
    "dumies = pd.get_dummies(test_df, columns=['segment'])\n",
    "check_df = check_df.join(dumies)\n",
    "test_df = check_df"
   ],
   "metadata": {
    "id": "QNrzHHKczUKc",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:23.294841100Z",
     "start_time": "2023-10-08T09:18:23.239688900Z"
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.drop(['balance_amt_avg', 'balance_amt_min', 'ogrn_month','ogrn_year'], axis=1, inplace=True)\n",
    "test_df.drop(['balance_amt_avg', 'balance_amt_min', 'ogrn_month','ogrn_year'], axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "FMfSlDkW2vSH",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:23.349096600Z",
     "start_time": "2023-10-08T09:18:23.294841100Z"
    }
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "В данных есть признак - index_city_code\tкод города в почтовом индексе. Так как мы закодировали города, можно избавиться от этого признака, он будет создавать лишние зависимости"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.drop(['index_city_code'], axis=1, inplace=True)\n",
    "\n",
    "# повторим для тестовых данных\n",
    "test_df.drop(['index_city_code'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Заметим, что в наших данных есть такие признаки как sum_a_oper_1m и cnt_a_oper_1m - сумма операций типа А за месяц и их количество. Это распространяется и на другие типы операций. Сконструируем новый признак sum/cnt - средняя сумма операции типа A в месяц. Распространим эту логику на все типы операций."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "\n",
    "# для операций типа A, B, C за 1 месяц\n",
    "train_df['med_sum_oper_a_1m'] = train_df['sum_a_oper_1m']/train_df['cnt_a_oper_1m']\n",
    "train_df.drop(['sum_a_oper_1m', 'cnt_a_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_oper_b_3m'] = train_df['sum_b_oper_3m']/train_df['cnt_b_oper_3m']\n",
    "train_df.drop(['sum_b_oper_1m', 'cnt_b_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_oper_c_1m'] = train_df['sum_c_oper_1m']/train_df['cnt_c_oper_1m']\n",
    "train_df.drop(['sum_c_oper_1m', 'cnt_c_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# для исходящих операций типа D, E, F, G, H за 1 месяц\n",
    "train_df['med_sum_deb_d_oper_1m'] = train_df['sum_deb_d_oper_1m']/train_df['cnt_deb_d_oper_1m']\n",
    "train_df.drop(['sum_deb_d_oper_1m', 'cnt_deb_d_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_deb_e_oper_1m'] = train_df['sum_deb_e_oper_1m']/train_df['cnt_deb_e_oper_1m']\n",
    "train_df.drop(['sum_deb_e_oper_1m', 'cnt_deb_e_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_deb_f_oper_1m'] = train_df['sum_deb_f_oper_1m']/train_df['cnt_deb_f_oper_1m']\n",
    "train_df.drop(['sum_deb_f_oper_1m', 'cnt_deb_f_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_deb_g_oper_1m'] = train_df['sum_deb_g_oper_1m']/train_df['cnt_deb_g_oper_1m']\n",
    "train_df.drop(['sum_deb_g_oper_1m', 'cnt_deb_g_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_deb_h_oper_1m'] = train_df['sum_deb_h_oper_1m']/train_df['cnt_deb_h_oper_1m']\n",
    "train_df.drop(['sum_deb_h_oper_1m', 'cnt_deb_h_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "# для входящих операций типа D, E, F, G, H  за 1 месяц\n",
    "train_df['med_sum_cred_d_oper_1m'] = train_df['sum_cred_d_oper_1m']/train_df['cnt_cred_d_oper_1m']\n",
    "train_df.drop(['sum_cred_d_oper_1m', 'cnt_cred_d_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_cred_e_oper_1m'] = train_df['sum_cred_e_oper_1m']/train_df['cnt_cred_e_oper_1m']\n",
    "train_df.drop(['sum_cred_e_oper_1m', 'cnt_cred_e_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_cred_f_oper_1m'] = train_df['sum_cred_f_oper_1m']/train_df['cnt_cred_f_oper_1m']\n",
    "train_df.drop(['sum_cred_f_oper_1m', 'cnt_cred_f_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_cred_g_oper_1m'] = train_df['sum_cred_g_oper_1m']/train_df['cnt_cred_g_oper_1m']\n",
    "train_df.drop(['sum_cred_g_oper_1m', 'cnt_cred_g_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_cred_h_oper_1m'] = train_df['sum_cred_h_oper_1m']/train_df['cnt_cred_h_oper_1m']\n",
    "train_df.drop(['sum_cred_h_oper_1m', 'cnt_cred_h_oper_1m'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:23.968736200Z",
     "start_time": "2023-10-08T09:18:23.349096600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# повторим для тестовых данных\n",
    "\n",
    "# для операций типа A, B, C за 1 месяц\n",
    "test_df['med_sum_oper_a_1m'] = test_df['sum_a_oper_1m']/test_df['cnt_a_oper_1m']\n",
    "test_df.drop(['sum_a_oper_1m', 'cnt_a_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_oper_b_3m'] = test_df['sum_b_oper_3m']/test_df['cnt_b_oper_3m']\n",
    "test_df.drop(['sum_b_oper_1m', 'cnt_b_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_oper_c_1m'] = test_df['sum_c_oper_1m']/test_df['cnt_c_oper_1m']\n",
    "test_df.drop(['sum_c_oper_1m', 'cnt_c_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "# для исходящих операций типа D, E, F, G, H за 1 месяц\n",
    "test_df['med_sum_deb_d_oper_1m'] = test_df['sum_deb_d_oper_1m']/test_df['cnt_deb_d_oper_1m']\n",
    "test_df.drop(['sum_deb_d_oper_1m', 'cnt_deb_d_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_deb_e_oper_1m'] = test_df['sum_deb_e_oper_1m']/test_df['cnt_deb_e_oper_1m']\n",
    "test_df.drop(['sum_deb_e_oper_1m', 'cnt_deb_e_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_deb_f_oper_1m'] = test_df['sum_deb_f_oper_1m']/test_df['cnt_deb_f_oper_1m']\n",
    "test_df.drop(['sum_deb_f_oper_1m', 'cnt_deb_f_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_deb_g_oper_1m'] = test_df['sum_deb_g_oper_1m']/test_df['cnt_deb_g_oper_1m']\n",
    "test_df.drop(['sum_deb_g_oper_1m', 'cnt_deb_g_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_deb_h_oper_1m'] = test_df['sum_deb_h_oper_1m']/test_df['cnt_deb_h_oper_1m']\n",
    "test_df.drop(['sum_deb_h_oper_1m', 'cnt_deb_h_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "# для входящих операций типа D, E, F, G, H за 1 месяц\n",
    "test_df['med_sum_cred_d_oper_1m'] = test_df['sum_cred_d_oper_1m']/test_df['cnt_cred_d_oper_1m']\n",
    "test_df.drop(['sum_cred_d_oper_1m', 'cnt_cred_d_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_cred_e_oper_1m'] = test_df['sum_cred_e_oper_1m']/test_df['cnt_cred_e_oper_1m']\n",
    "test_df.drop(['sum_cred_e_oper_1m', 'cnt_cred_e_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_cred_f_oper_1m'] = test_df['sum_cred_f_oper_1m']/test_df['cnt_cred_f_oper_1m']\n",
    "test_df.drop(['sum_cred_f_oper_1m', 'cnt_cred_f_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_cred_g_oper_1m'] = test_df['sum_cred_g_oper_1m']/test_df['cnt_cred_g_oper_1m']\n",
    "test_df.drop(['sum_cred_g_oper_1m', 'cnt_cred_g_oper_1m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_cred_h_oper_1m'] = test_df['sum_cred_h_oper_1m']/test_df['cnt_cred_h_oper_1m']\n",
    "test_df.drop(['sum_cred_h_oper_1m', 'cnt_cred_h_oper_1m'], axis=1, inplace=True)\n",
    "\n"
   ],
   "metadata": {
    "id": "-G5USpPgBBUN",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:24.151557400Z",
     "start_time": "2023-10-08T09:18:23.953025700Z"
    }
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Аналогично заменим признаки суммы и количества операций разного типа для 3 месяцев"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# для операций типа A, B, C\n",
    "train_df['med_sum_oper_a_3m'] = train_df['sum_a_oper_3m']/train_df['cnt_a_oper_3m']\n",
    "train_df.drop(['sum_a_oper_3m', 'cnt_a_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_oper_b_3m'] = train_df['sum_b_oper_3m']/train_df['cnt_b_oper_3m']\n",
    "train_df.drop(['sum_b_oper_3m', 'cnt_b_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_oper_c_3m'] = train_df['sum_c_oper_3m']/train_df['cnt_c_oper_3m']\n",
    "train_df.drop(['sum_c_oper_3m', 'cnt_c_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "# для исходящих операций типа D, E, F, G, H\n",
    "train_df['med_sum_deb_d_oper_3m'] = train_df['sum_deb_d_oper_3m']/train_df['cnt_deb_d_oper_3m']\n",
    "train_df.drop(['sum_deb_d_oper_3m', 'cnt_deb_d_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_deb_e_oper_3m'] = train_df['sum_deb_e_oper_3m']/train_df['cnt_deb_e_oper_3m']\n",
    "train_df.drop(['sum_deb_e_oper_3m', 'cnt_deb_e_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_deb_f_oper_3m'] = train_df['sum_deb_f_oper_3m']/train_df['cnt_deb_f_oper_3m']\n",
    "train_df.drop(['sum_deb_f_oper_3m', 'cnt_deb_f_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_deb_g_oper_3m'] = train_df['sum_deb_g_oper_3m']/train_df['cnt_deb_g_oper_3m']\n",
    "train_df.drop(['sum_deb_g_oper_3m', 'cnt_deb_g_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_deb_h_oper_3m'] = train_df['sum_deb_h_oper_3m']/train_df['cnt_deb_h_oper_3m']\n",
    "train_df.drop(['sum_deb_h_oper_3m', 'cnt_deb_h_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "# для входящих операций типа D, E, F, G, H\n",
    "train_df['med_sum_cred_d_oper_3m'] = train_df['sum_cred_d_oper_3m']/train_df['cnt_cred_d_oper_3m']\n",
    "train_df.drop(['sum_cred_d_oper_3m', 'cnt_cred_d_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_cred_e_oper_3m'] = train_df['sum_cred_e_oper_3m']/train_df['cnt_cred_e_oper_3m']\n",
    "train_df.drop(['sum_cred_e_oper_3m', 'cnt_cred_e_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_cred_f_oper_3m'] = train_df['sum_cred_f_oper_3m']/train_df['cnt_cred_f_oper_3m']\n",
    "train_df.drop(['sum_cred_f_oper_3m', 'cnt_cred_f_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_cred_g_oper_3m'] = train_df['sum_cred_g_oper_3m']/train_df['cnt_cred_g_oper_3m']\n",
    "train_df.drop(['sum_cred_g_oper_3m', 'cnt_cred_g_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "train_df['med_sum_cred_h_oper_3m'] = train_df['sum_cred_h_oper_3m']/train_df['cnt_cred_h_oper_3m']\n",
    "train_df.drop(['sum_cred_h_oper_3m', 'cnt_cred_h_oper_3m'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:24.734546900Z",
     "start_time": "2023-10-08T09:18:24.151557400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# для операций типа A, B, C за 3 месяца\n",
    "test_df['med_sum_oper_a_3m'] = test_df['sum_a_oper_3m']/test_df['cnt_a_oper_3m']\n",
    "test_df.drop(['sum_a_oper_3m', 'cnt_a_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_oper_b_3m'] = test_df['sum_b_oper_3m']/test_df['cnt_b_oper_3m']\n",
    "test_df.drop(['sum_b_oper_3m', 'cnt_b_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_oper_c_3m'] = test_df['sum_c_oper_3m']/test_df['cnt_c_oper_3m']\n",
    "test_df.drop(['sum_c_oper_3m', 'cnt_c_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "# для исходящих операций типа D, E, F, G, H за 3 месяца\n",
    "test_df['med_sum_deb_d_oper_3m'] = test_df['sum_deb_d_oper_3m']/test_df['cnt_deb_d_oper_3m']\n",
    "test_df.drop(['sum_deb_d_oper_3m', 'cnt_deb_d_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_deb_e_oper_3m'] = test_df['sum_deb_e_oper_3m']/test_df['cnt_deb_e_oper_3m']\n",
    "test_df.drop(['sum_deb_e_oper_3m', 'cnt_deb_e_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_deb_f_oper_3m'] = test_df['sum_deb_f_oper_3m']/test_df['cnt_deb_f_oper_3m']\n",
    "test_df.drop(['sum_deb_f_oper_3m', 'cnt_deb_f_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_deb_g_oper_3m'] = test_df['sum_deb_g_oper_3m']/test_df['cnt_deb_g_oper_3m']\n",
    "test_df.drop(['sum_deb_g_oper_3m', 'cnt_deb_g_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_deb_h_oper_3m'] = test_df['sum_deb_h_oper_3m']/test_df['cnt_deb_h_oper_3m']\n",
    "test_df.drop(['sum_deb_h_oper_3m', 'cnt_deb_h_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "# для входящих операций типа D, E, F, G, H за 3 месяца\n",
    "test_df['med_sum_cred_d_oper_3m'] = test_df['sum_cred_d_oper_3m']/test_df['cnt_cred_d_oper_3m']\n",
    "test_df.drop(['sum_cred_d_oper_3m', 'cnt_cred_d_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_cred_e_oper_3m'] = test_df['sum_cred_e_oper_3m']/test_df['cnt_cred_e_oper_3m']\n",
    "test_df.drop(['sum_cred_e_oper_3m', 'cnt_cred_e_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_cred_f_oper_3m'] = test_df['sum_cred_f_oper_3m']/test_df['cnt_cred_f_oper_3m']\n",
    "test_df.drop(['sum_cred_f_oper_3m', 'cnt_cred_f_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_cred_g_oper_3m'] = test_df['sum_cred_g_oper_3m']/test_df['cnt_cred_g_oper_3m']\n",
    "test_df.drop(['sum_cred_g_oper_3m', 'cnt_cred_g_oper_3m'], axis=1, inplace=True)\n",
    "\n",
    "test_df['med_sum_cred_h_oper_3m'] = test_df['sum_cred_h_oper_3m']/test_df['cnt_cred_h_oper_3m']\n",
    "test_df.drop(['sum_cred_h_oper_3m', 'cnt_cred_h_oper_3m'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:24.955593Z",
     "start_time": "2023-10-08T09:18:24.734546900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Обработаем выбросы с помощью изолированного дерева"
   ],
   "metadata": {
    "id": "UzPsva-GBOX0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Выберем признаки, в которых не будет происходить поиск аномалий (категориальные признаки)\n",
    "cat_cols = [\n",
    "    'channel_code', 'city', 'city_type',\n",
    "    'branch_code', 'okved'\n",
    "]\n",
    "\n",
    "# Отфильтруем категориальные признаки из всех признаков\n",
    "no_anomaly_features = [col for col in train_df.columns if col not in cat_cols]\n",
    "\n",
    "\n",
    "df_to_filter = train_df[no_anomaly_features]\n",
    "iso_clf = IsolationForest(random_state=42, contamination=0.2).fit(df_to_filter)\n",
    "anomaly = iso_clf.predict(df_to_filter)\n",
    "\n",
    "# Отфильтруем только те строки, которые не являются аномалиями\n",
    "train_df_filtered = train_df[anomaly == 1]\n",
    "\n",
    "# Присоединим отфильтрованные числовые данные к категориальным данным\n",
    "train_df_filtered_with_categorical = train_df_filtered[cat_cols].join(train_df_filtered[no_anomaly_features])\n",
    "\n",
    "print(train_df_filtered_with_categorical.shape)\n",
    "\n",
    "train_df = train_df_filtered_with_categorical"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z2Du2-YfBPtE",
    "outputId": "ab0a6871-eedc-4194-8d25-35fc90bb3801",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.251518600Z",
     "start_time": "2023-10-08T09:18:24.956586200Z"
    }
   },
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 70)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь отберем признаки\n",
    "Для начала выделим в отдельные переменные столбцы target_1, target_2 и target"
   ],
   "metadata": {
    "collapsed": false,
    "id": "mPu5PSLxdy6c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "target_1 = train_df['target_1']\n",
    "target_2 = train_df['target_2']\n",
    "target = train_df['total_target']\n",
    "\n",
    "train_df.drop(['target_1', 'target_2', 'total_target'], axis=1, inplace=True)"
   ],
   "metadata": {
    "id": "Oc_FFBhqdy6c",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.308319700Z",
     "start_time": "2023-10-08T09:18:28.250518700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь определим меру взаимной информации для признаков, чтобы понять какие из признаков действительно оказывают влияние на модель"
   ],
   "metadata": {
    "collapsed": false,
    "id": "B6lo0dFgdy6e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# names = [column for column in train_df]\n",
    "# X = train_df[names[:90]]\n",
    "\n",
    "# # для target_1\n",
    "# y1 = target_1.to_numpy().ravel()\n",
    "\n",
    "# # mi_1 = mutual_info_classif(X, y1)\n",
    "\n",
    "# mi_sc_1 = pd.Series(mi_1, name=\"MI Scores\", index=X.columns)\n",
    "# mi_sc_1 = mi_sc_1.sort_values(ascending=False)\n",
    "\n",
    "# # head используем, чтобы получить самые влиятельные, tail - наименее влиятельные\n",
    "# print('Наиболее влиятельные признаки для target_1')\n",
    "# mi_sc_1"
   ],
   "metadata": {
    "id": "xi6tgDY2dy6e",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.315154300Z",
     "start_time": "2023-10-08T09:18:28.291493300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# # для target_2\n",
    "# y2 = target_2.to_numpy().ravel()\n",
    "\n",
    "# mi_2 = mutual_info_classif(X, y2)\n",
    "\n",
    "# mi_sc_2 = pd.Series(mi_2, name=\"MI Scores\", index=X.columns)\n",
    "# mi_sc_2 = mi_sc_2.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "# # head используем чтобы получить самые влиятельные, tail - наименее влиятельные\n",
    "# print('Наиболее влиятельные признаки для target_2')\n",
    "# mi_sc_2"
   ],
   "metadata": {
    "id": "luI613CNdy6f",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.315154300Z",
     "start_time": "2023-10-08T09:18:28.294556900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Теперь, когда мы знаем какие признаки не влияют на подсчет первого и второго таргета, мы можем их удалить и получить соответствующие датасеты для target_1 и target_2"
   ],
   "metadata": {
    "collapsed": false,
    "id": "A72bX5oNdy6f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# zero_mi_cols_1 = mi_sc_1[mi_sc_1 <= 0.015].index.tolist()\n",
    "# X1_train = train_df.drop(columns=zero_mi_cols_1)\n",
    "\n",
    "# zero_mi_cols_2 = mi_sc_2[mi_sc_2 <= 0.015].index.tolist()\n",
    "# X2_train = train_df.drop(columns=zero_mi_cols_2)"
   ],
   "metadata": {
    "id": "cvfs5MF4dy6g",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.315154300Z",
     "start_time": "2023-10-08T09:18:28.297990200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Повторим эти действия для тестовой выборки"
   ],
   "metadata": {
    "collapsed": false,
    "id": "rxvHY3_Kdy6g"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# X1_test = test_df.drop(columns=zero_mi_cols_1)\n",
    "# X2_test = test_df.drop(columns=zero_mi_cols_2)"
   ],
   "metadata": {
    "id": "zCthrzaKdy6g",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.315154300Z",
     "start_time": "2023-10-08T09:18:28.299833500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Обучение модели"
   ],
   "metadata": {
    "collapsed": false,
    "id": "J7WYYihjdy6g"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "# import optuna\n"
   ],
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "id": "acbR_mCUdy6l",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.316155800Z",
     "start_time": "2023-10-08T09:18:28.304778Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "# train_df = train_df.drop(['okved_47'],axis=1,inplace=True)\n",
    "# Для target_1\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(train_df, target_1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Для target_2\n",
    "x2_train, x2_test, y2_train, y2_test = train_test_split(train_df, target_2, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "id": "3nNr6uIa3JMb",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.556311800Z",
     "start_time": "2023-10-08T09:18:28.306283300Z"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Kyp_LV-UmLxZ",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.558868Z",
     "start_time": "2023-10-08T09:18:28.556311800Z"
    }
   },
   "execution_count": 58,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'eval_metric':trial.suggest_categorical('eval_metric', ['mlogloss']),\n",
    "    }\n",
    "\n",
    "\n",
    "    model_xgb = XGBClassifier(device='cuda', enable_categorical=True, n_jobs=-1, **params)\n",
    "    model_xgb.fit(x1_train, y1_train)\n",
    "    y_pred_1 = model_xgb.predict_proba(x1_test)[:,1]\n",
    "    scores = roc_auc_score(y1_test,y_pred_1)\n",
    "\n",
    "\n",
    "    return scores"
   ],
   "metadata": {
    "id": "UDGWW5lMw3fv",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.565060300Z",
     "start_time": "2023-10-08T09:18:28.559868700Z"
    }
   },
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def objective_xgb_t2(trial):\n",
    "    params = {\n",
    "        'booster': trial.suggest_categorical('booster', ['gbtree']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 5000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'eval_metric':trial.suggest_categorical('eval_metric', ['mlogloss']),\n",
    "    }\n",
    "\n",
    "\n",
    "    model_t2 = XGBClassifier(device='cuda', enable_categorical=True, n_jobs=-1, **params)\n",
    "    model_t2.fit(x2_train, y2_train)\n",
    "    y_pred_2 = model_t2.predict_proba(x2_test)[:,1]\n",
    "    scores = roc_auc_score(y2_test,y_pred_2)\n",
    "\n",
    "\n",
    "    return scores\n"
   ],
   "metadata": {
    "id": "yPsbQeRihMdS",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:28.573915500Z",
     "start_time": "2023-10-08T09:18:28.562992600Z"
    }
   },
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "study_xgb = optuna.create_study(study_name='target_1', direction='maximize')\n",
    "study_xgb.optimize(objective_xgb, n_trials=100,show_progress_bar=True, n_jobs=-1)\n",
    "study_xgb.best_params"
   ],
   "metadata": {
    "id": "hKCaDveZxFDz",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277,
     "referenced_widgets": [
      "da65920cb76f456184f0b543caeba511",
      "5ab5968de26846b6ad8b38ba2655c9f0",
      "b76f5f42e74a4d7f9afca146f19ab568",
      "9c16ba47e2b546898aede433193de81a",
      "fb775df432da44b5a1fa7e21a110928c",
      "0083ceaf28d54bcdb85372f025b46fd3",
      "04b9680492c8481ea25eb67b3ab920a8",
      "cb48378ac2c949f0959e29a5379810ea",
      "86f8e048eff3419191cde24863533390",
      "d3b26ba7d8ef46ea85ce29ef14c594a4",
      "7984ea8d8eaf41b3acfed7abcb8435c1"
     ]
    },
    "outputId": "6833c619-cc37-4d53-ea52-231da59c1494",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:29.339627100Z",
     "start_time": "2023-10-08T09:18:28.573915500Z"
    }
   },
   "execution_count": 61,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-10-08 11:18:28,575] A new study created in memory with name: target_1\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a357046515424ef18527859ab131631f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2023-10-08 11:18:28,594] Trial 2 failed with parameters: {'booster': 'gbtree', 'max_depth': 8, 'learning_rate': 0.9859907634696853, 'n_estimators': 3563, 'min_child_weight': 4, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,594] Trial 1 failed with parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.27422186277452604, 'n_estimators': 615, 'min_child_weight': 2, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,598] Trial 0 failed with parameters: {'booster': 'gbtree', 'max_depth': 10, 'learning_rate': 0.016078335466404983, 'n_estimators': 1321, 'min_child_weight': 8, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,600] Trial 3 failed with parameters: {'booster': 'gbtree', 'max_depth': 14, 'learning_rate': 0.09397103928881494, 'n_estimators': 3211, 'min_child_weight': 7, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,601] Trial 7 failed with parameters: {'booster': 'gbtree', 'max_depth': 12, 'learning_rate': 0.1096757204379073, 'n_estimators': 2889, 'min_child_weight': 5, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,601] Trial 4 failed with parameters: {'booster': 'gbtree', 'max_depth': 15, 'learning_rate': 0.22407354425923648, 'n_estimators': 4215, 'min_child_weight': 1, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,602] Trial 6 failed with parameters: {'booster': 'gbtree', 'max_depth': 10, 'learning_rate': 0.019174723659938588, 'n_estimators': 2761, 'min_child_weight': 7, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,603] Trial 5 failed with parameters: {'booster': 'gbtree', 'max_depth': 15, 'learning_rate': 0.024248488302673496, 'n_estimators': 4483, 'min_child_weight': 10, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,605] Trial 8 failed with parameters: {'booster': 'gbtree', 'max_depth': 14, 'learning_rate': 0.330797367211944, 'n_estimators': 496, 'min_child_weight': 6, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,605] Trial 9 failed with parameters: {'booster': 'gbtree', 'max_depth': 14, 'learning_rate': 0.048553414647626005, 'n_estimators': 3745, 'min_child_weight': 4, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,606] Trial 10 failed with parameters: {'booster': 'gbtree', 'max_depth': 12, 'learning_rate': 0.47301456339198233, 'n_estimators': 2476, 'min_child_weight': 4, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,608] Trial 11 failed with parameters: {'booster': 'gbtree', 'max_depth': 14, 'learning_rate': 0.05029549092486218, 'n_estimators': 1888, 'min_child_weight': 10, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,608] Trial 12 failed with parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.0467275488083824, 'n_estimators': 3856, 'min_child_weight': 5, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,609] Trial 14 failed with parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.11188393435244828, 'n_estimators': 2448, 'min_child_weight': 7, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,609] Trial 13 failed with parameters: {'booster': 'gbtree', 'max_depth': 7, 'learning_rate': 0.01429285125290765, 'n_estimators': 2253, 'min_child_weight': 5, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,611] Trial 15 failed with parameters: {'booster': 'gbtree', 'max_depth': 5, 'learning_rate': 0.17051555557240133, 'n_estimators': 2905, 'min_child_weight': 8, 'eval_metric': 'mlogloss'} because of the following error: ValueError('Experimental support for categorical data is not implemented for current tree method yet.').\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\serpr\\AppData\\Local\\Temp\\ipykernel_9924\\3575804054.py\", line 13, in objective_xgb\n",
      "    model_xgb.fit(x1_train, y1_train)\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1468, in fit\n",
      "    ) = self._configure_fit(\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"E:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py\", line 892, in _configure_fit\n",
      "    raise ValueError(\n",
      "ValueError: Experimental support for categorical data is not implemented for current tree method yet.\n",
      "[W 2023-10-08 11:18:28,611] Trial 2 failed with value None.\n",
      "[W 2023-10-08 11:18:28,612] Trial 1 failed with value None.\n",
      "[W 2023-10-08 11:18:28,613] Trial 0 failed with value None.\n",
      "[W 2023-10-08 11:18:28,614] Trial 3 failed with value None.\n",
      "[W 2023-10-08 11:18:28,615] Trial 7 failed with value None.\n",
      "[W 2023-10-08 11:18:28,617] Trial 4 failed with value None.\n",
      "[W 2023-10-08 11:18:28,618] Trial 6 failed with value None.\n",
      "[W 2023-10-08 11:18:28,619] Trial 5 failed with value None.\n",
      "[W 2023-10-08 11:18:28,621] Trial 8 failed with value None.\n",
      "[W 2023-10-08 11:18:28,622] Trial 9 failed with value None.\n",
      "[W 2023-10-08 11:18:28,623] Trial 10 failed with value None.\n",
      "[W 2023-10-08 11:18:28,624] Trial 11 failed with value None.\n",
      "[W 2023-10-08 11:18:28,626] Trial 12 failed with value None.\n",
      "[W 2023-10-08 11:18:28,627] Trial 14 failed with value None.\n",
      "[W 2023-10-08 11:18:28,628] Trial 13 failed with value None.\n",
      "[W 2023-10-08 11:18:28,641] Trial 15 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Experimental support for categorical data is not implemented for current tree method yet.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[61], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m study_xgb \u001B[38;5;241m=\u001B[39m optuna\u001B[38;5;241m.\u001B[39mcreate_study(study_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtarget_1\u001B[39m\u001B[38;5;124m'\u001B[39m, direction\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmaximize\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m study_xgb\u001B[38;5;241m.\u001B[39moptimize(objective_xgb, n_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m,show_progress_bar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      3\u001B[0m study_xgb\u001B[38;5;241m.\u001B[39mbest_params\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\study.py:442\u001B[0m, in \u001B[0;36mStudy.optimize\u001B[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    339\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moptimize\u001B[39m(\n\u001B[0;32m    340\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    341\u001B[0m     func: ObjectiveFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    350\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[0;32m    351\u001B[0m \n\u001B[0;32m    352\u001B[0m \u001B[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;124;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[0;32m    441\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 442\u001B[0m     _optimize(\n\u001B[0;32m    443\u001B[0m         study\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    444\u001B[0m         func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m    445\u001B[0m         n_trials\u001B[38;5;241m=\u001B[39mn_trials,\n\u001B[0;32m    446\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[0;32m    447\u001B[0m         n_jobs\u001B[38;5;241m=\u001B[39mn_jobs,\n\u001B[0;32m    448\u001B[0m         catch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mtuple\u001B[39m(catch) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(catch, Iterable) \u001B[38;5;28;01melse\u001B[39;00m (catch,),\n\u001B[0;32m    449\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[0;32m    450\u001B[0m         gc_after_trial\u001B[38;5;241m=\u001B[39mgc_after_trial,\n\u001B[0;32m    451\u001B[0m         show_progress_bar\u001B[38;5;241m=\u001B[39mshow_progress_bar,\n\u001B[0;32m    452\u001B[0m     )\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py:103\u001B[0m, in \u001B[0;36m_optimize\u001B[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[0m\n\u001B[0;32m    101\u001B[0m                     \u001B[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001B[39;00m\n\u001B[0;32m    102\u001B[0m                     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m completed:\n\u001B[1;32m--> 103\u001B[0m                         f\u001B[38;5;241m.\u001B[39mresult()\n\u001B[0;32m    105\u001B[0m                 futures\u001B[38;5;241m.\u001B[39madd(\n\u001B[0;32m    106\u001B[0m                     executor\u001B[38;5;241m.\u001B[39msubmit(\n\u001B[0;32m    107\u001B[0m                         _optimize_sequential,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    118\u001B[0m                     )\n\u001B[0;32m    119\u001B[0m                 )\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\concurrent\\futures\\_base.py:449\u001B[0m, in \u001B[0;36mFuture.result\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m--> 449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\concurrent\\futures\\_base.py:401\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[0;32m    400\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    403\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[0;32m    404\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\concurrent\\futures\\thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[0m, in \u001B[0;36m_optimize_sequential\u001B[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[0m\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 163\u001B[0m     frozen_trial \u001B[38;5;241m=\u001B[39m _run_trial(study, func, catch)\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    244\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShould not reach.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    247\u001B[0m     frozen_trial\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m==\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mFAIL\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[0;32m    250\u001B[0m ):\n\u001B[1;32m--> 251\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[0;32m    252\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001B[0m, in \u001B[0;36m_run_trial\u001B[1;34m(study, func, catch)\u001B[0m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial\u001B[38;5;241m.\u001B[39m_trial_id, study\u001B[38;5;241m.\u001B[39m_storage):\n\u001B[0;32m    199\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 200\u001B[0m         value_or_values \u001B[38;5;241m=\u001B[39m func(trial)\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions\u001B[38;5;241m.\u001B[39mTrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    202\u001B[0m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[0;32m    203\u001B[0m         state \u001B[38;5;241m=\u001B[39m TrialState\u001B[38;5;241m.\u001B[39mPRUNED\n",
      "Cell \u001B[1;32mIn[59], line 13\u001B[0m, in \u001B[0;36mobjective_xgb\u001B[1;34m(trial)\u001B[0m\n\u001B[0;32m      2\u001B[0m params \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbooster\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_categorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbooster\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgbtree\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m: trial\u001B[38;5;241m.\u001B[39msuggest_int(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax_depth\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m15\u001B[39m),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124meval_metric\u001B[39m\u001B[38;5;124m'\u001B[39m:trial\u001B[38;5;241m.\u001B[39msuggest_categorical(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124meval_metric\u001B[39m\u001B[38;5;124m'\u001B[39m, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmlogloss\u001B[39m\u001B[38;5;124m'\u001B[39m]),\n\u001B[0;32m      9\u001B[0m }\n\u001B[0;32m     12\u001B[0m model_xgb \u001B[38;5;241m=\u001B[39m XGBClassifier(device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m, enable_categorical\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[1;32m---> 13\u001B[0m model_xgb\u001B[38;5;241m.\u001B[39mfit(x1_train, y1_train)\n\u001B[0;32m     14\u001B[0m y_pred_1 \u001B[38;5;241m=\u001B[39m model_xgb\u001B[38;5;241m.\u001B[39mpredict_proba(x1_test)[:,\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     15\u001B[0m scores \u001B[38;5;241m=\u001B[39m roc_auc_score(y1_test,y_pred_1)\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[0;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[1;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py:1468\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[0;32m   1459\u001B[0m         params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobjective\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti:softprob\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1460\u001B[0m     params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_class\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_\n\u001B[0;32m   1462\u001B[0m (\n\u001B[0;32m   1463\u001B[0m     model,\n\u001B[0;32m   1464\u001B[0m     metric,\n\u001B[0;32m   1465\u001B[0m     params,\n\u001B[0;32m   1466\u001B[0m     early_stopping_rounds,\n\u001B[0;32m   1467\u001B[0m     callbacks,\n\u001B[1;32m-> 1468\u001B[0m ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_configure_fit(\n\u001B[0;32m   1469\u001B[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001B[0;32m   1470\u001B[0m )\n\u001B[0;32m   1471\u001B[0m train_dmatrix, evals \u001B[38;5;241m=\u001B[39m _wrap_evaluation_matrices(\n\u001B[0;32m   1472\u001B[0m     missing\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmissing,\n\u001B[0;32m   1473\u001B[0m     X\u001B[38;5;241m=\u001B[39mX,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1487\u001B[0m     feature_types\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeature_types,\n\u001B[0;32m   1488\u001B[0m )\n\u001B[0;32m   1490\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_Booster \u001B[38;5;241m=\u001B[39m train(\n\u001B[0;32m   1491\u001B[0m     params,\n\u001B[0;32m   1492\u001B[0m     train_dmatrix,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1501\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[0;32m   1502\u001B[0m )\n",
      "File \u001B[1;32mE:\\shizofrenia\\Anaconda\\Lib\\site-packages\\xgboost\\sklearn.py:892\u001B[0m, in \u001B[0;36mXGBModel._configure_fit\u001B[1;34m(self, booster, eval_metric, params, early_stopping_rounds, callbacks)\u001B[0m\n\u001B[0;32m    890\u001B[0m cat_support \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu_hist\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapprox\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhist\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[0;32m    891\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menable_categorical \u001B[38;5;129;01mand\u001B[39;00m tree_method \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m cat_support:\n\u001B[1;32m--> 892\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    893\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExperimental support for categorical data is not implemented for\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    894\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m current tree method yet.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    895\u001B[0m     )\n\u001B[0;32m    897\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model, metric, params, early_stopping_rounds, callbacks\n",
      "\u001B[1;31mValueError\u001B[0m: Experimental support for categorical data is not implemented for current tree method yet."
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "study_xgb_t2 = optuna.create_study(study_name='target_2',direction='maximize')\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_xgb_t2.optimize(objective_xgb_t2, n_trials=100,show_progress_bar=True)\n"
   ],
   "metadata": {
    "id": "dM4bGgOhhSkH",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:29.339627100Z",
     "start_time": "2023-10-08T09:18:29.339627100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Target_1"
   ],
   "metadata": {
    "id": "bhAow8GNo5T3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = XGBClassifier(enable_categorical=True, device='cuda', **study_xgb.best_params)\n",
    "model.fit(x1_train, y1_train)\n",
    "\n",
    "y_pred_1 = model.predict_proba(x1_test)[:,1]\n",
    "\n",
    "accuracy = roc_auc_score(y1_test, y_pred_1)\n",
    "print(\"Xgboost Accuracy:\", accuracy)"
   ],
   "metadata": {
    "id": "yv2o875oKkH5",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:29.342670100Z",
     "start_time": "2023-10-08T09:18:29.340628Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Target_2"
   ],
   "metadata": {
    "id": "Pzw0BJv1o7oF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model_t2 = XGBClassifier(enable_categorical=True, device='cuda', **study_xgb_t2.best_params)\n",
    "model_t2.fit(x2_train, y2_train)\n",
    "\n",
    "y_pred_2 = model_t2.predict_proba(x2_test)[:,1]\n",
    "accuracy = roc_auc_score(y2_test, y_pred_2)\n",
    "print(\"Xgboost Accuracy:\", accuracy)"
   ],
   "metadata": {
    "id": "WQJ7H0kSo83x",
    "ExecuteTime": {
     "start_time": "2023-10-08T09:18:29.341670400Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Запуск на тестовых данных\n"
   ],
   "metadata": {
    "id": "ERjMNe9g3Bd_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df = test_df[[x for x in x1_test.columns]]\n",
    "df2= test_df[[x for x in train_df.columns]]"
   ],
   "metadata": {
    "id": "6lOFrNzyXRrK",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:29.342670100Z",
     "start_time": "2023-10-08T09:18:29.342670100Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# target_1\n",
    "y_pred_1 = model.predict_proba(df)[:,1]\n",
    "y_pred_1"
   ],
   "metadata": {
    "id": "5MV_l45f5God",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:29.344628600Z",
     "start_time": "2023-10-08T09:18:29.343671600Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred_2 =  model_t2.predict_proba(df2)[:,1]\n",
    "len(y_pred_2)"
   ],
   "metadata": {
    "id": "4XI8aHQ354Ix",
    "ExecuteTime": {
     "end_time": "2023-10-08T09:18:29.346628900Z",
     "start_time": "2023-10-08T09:18:29.344628600Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame(columns=['id', 'target1', 'target2', 'score'])\n",
    "df['id'] = test_df['id']\n",
    "df['target1'] = y_pred_1\n",
    "df['target2'] = y_pred_2\n",
    "score = []\n",
    "\n",
    "for index, item in enumerate(y_pred_1):\n",
    "  score.append(max(item, y_pred_2[index]))\n",
    "\n",
    "df['score'] = score\n",
    "df.drop(['target1', 'target2'], axis=1, inplace=True)\n",
    "df.to_csv('/content/drive/MyDrive/out15.csv', index=False)"
   ],
   "metadata": {
    "id": "IQPKFGGe56oi",
    "ExecuteTime": {
     "start_time": "2023-10-08T09:18:29.345627700Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "peP1MFXjEY2C",
    "ExecuteTime": {
     "start_time": "2023-10-08T09:18:29.346628900Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "da65920cb76f456184f0b543caeba511": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5ab5968de26846b6ad8b38ba2655c9f0",
       "IPY_MODEL_b76f5f42e74a4d7f9afca146f19ab568",
       "IPY_MODEL_9c16ba47e2b546898aede433193de81a"
      ],
      "layout": "IPY_MODEL_fb775df432da44b5a1fa7e21a110928c"
     }
    },
    "5ab5968de26846b6ad8b38ba2655c9f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0083ceaf28d54bcdb85372f025b46fd3",
      "placeholder": "​",
      "style": "IPY_MODEL_04b9680492c8481ea25eb67b3ab920a8",
      "value": "Best trial: 0. Best value: 0.918215:   3%"
     }
    },
    "b76f5f42e74a4d7f9afca146f19ab568": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb48378ac2c949f0959e29a5379810ea",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86f8e048eff3419191cde24863533390",
      "value": 3
     }
    },
    "9c16ba47e2b546898aede433193de81a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3b26ba7d8ef46ea85ce29ef14c594a4",
      "placeholder": "​",
      "style": "IPY_MODEL_7984ea8d8eaf41b3acfed7abcb8435c1",
      "value": " 3/100 [02:40&lt;1:36:36, 59.76s/it]"
     }
    },
    "fb775df432da44b5a1fa7e21a110928c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0083ceaf28d54bcdb85372f025b46fd3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04b9680492c8481ea25eb67b3ab920a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb48378ac2c949f0959e29a5379810ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86f8e048eff3419191cde24863533390": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3b26ba7d8ef46ea85ce29ef14c594a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7984ea8d8eaf41b3acfed7abcb8435c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
